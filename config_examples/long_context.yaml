# Long Context Testing Configuration

output:
  file: "workload_long_context.json"
  num_requests: 1000

prompt_distribution:
  short:
    percentage: 0
    min_tokens: 10
    max_tokens: 128
  medium:
    percentage: 30
    min_tokens: 512
    max_tokens: 1024
  long:
    percentage: 70
    min_tokens: 1024
    max_tokens: 4096

completion_distribution:
  short:
    percentage: 0
    min_tokens: 10
    max_tokens: 64
  medium:
    percentage: 40
    min_tokens: 256
    max_tokens: 512
  long:
    percentage: 60
    min_tokens: 512
    max_tokens: 2048

arrival_pattern:
  type: "poisson"
  rate: 2.0

data_sources:
  - name: "sharegpt"
    path: "datasets/sharegpt.jsonl"
    weight: 0.6
    enabled: true
  - name: "alpaca"
    path: "datasets/alpaca.jsonl"
    weight: 0.4
    enabled: true
  - name: "mmlu"
    path: "datasets/mmlu.jsonl"
    weight: 0.0
    enabled: false
  - name: "custom"
    path: "datasets/custom.jsonl"
    weight: 0.0
    enabled: false

random_seed: 42

advanced:
  filter_duplicates: true
  shuffle_output: true
  include_metadata: true
  timestamp_start: 0.0


